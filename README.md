# SHAP-KDï¼šé¢å‘ä¿¡ç”¨é£é™©è¯„ä¼°çš„å¯è§£é‡ŠçŸ¥è¯†è’¸é¦

æœ¬ä»“åº“é…å¥—è®ºæ–‡å®ç°ï¼šåœ¨å››ä¸ªä¿¡ç”¨é£é™©æ•°æ®é›†ä¸Šè¿›è¡Œ**åŸºå‡†æ¨¡å‹å¯¹æ¯”**ã€**è‡ªåŠ¨æ•™å¸ˆé€‰æ‹©**ã€ä»¥åŠå°†æ•™å¸ˆçŸ¥è¯†è’¸é¦åˆ°**å•æ£µå†³ç­–æ ‘å­¦ç”Ÿ**çš„ **SHAP-KD**ï¼ˆå«å¯é€‰è‡ªé€‚åº”æ¸©åº¦å˜ä½“ï¼‰ï¼Œå¹¶è¾“å‡ºå¯å®¡è®¡çš„ IF-THEN è§„åˆ™ã€‚

## ä¸»è¦ç‰¹æ€§

- **åŸºå‡†æ¨¡å‹**ï¼šLR/SVM/RF/GBDT/XGBoost/LightGBM/CatBoostï¼ˆå¯é€‰ Optuna è°ƒå‚ï¼‰
- **ç¥ç»ç½‘ç»œåŸºçº¿**ï¼šCreditNet
- **SHAP-KD**ï¼šTeacher â†’ Decision Tree Studentï¼Œä½¿ç”¨æ¸©åº¦ç¼©æ”¾ soft labels + æ ·æœ¬æƒé‡è®­ç»ƒï¼ˆ`sample_weight`ï¼‰
- **è‡ªåŠ¨æ•™å¸ˆé€‰æ‹©**ï¼šåœ¨éªŒè¯é›†ä¸ŠåŸºäº AUC é€‰æ‹©æœ€ä¼˜ Teacher
- **è§„åˆ™å¯¼å‡º**ï¼šä»è’¸é¦åçš„æ ‘å¯¼å‡ºè·¯å¾„è§„åˆ™ï¼ˆæ–‡æœ¬ + Excelï¼‰
- **å¯è§£é‡Šæ€§å›¾**ï¼šå†³ç­–æ ‘ + SHAP é‡è¦æ€§å›¾ï¼ˆä¿å­˜åˆ°è®ºæ–‡ Figure ç›®å½•ï¼‰

## æ•°æ®é›†

| Dataset | Samples | Features | Source |
|---------|---------|----------|--------|
| German Credit | 1,000 | 20 | UCI |
| Australian Credit | 690 | 14 | UCI |
| Xinwang Credit | 17,884 | 100 | Chinese P2P |
| UCI Credit Card | 30,000 | 23 | UCI |

## å¿«é€Ÿå¼€å§‹

### 1) å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2) è¿è¡Œå®éªŒ

**æ¨èæ–¹å¼ï¼šä½¿ç”¨è§£è€¦çš„å®éªŒæµç¨‹**

```bash
# å®Œæ•´æµç¨‹ï¼šè®­ç»ƒæ•™å¸ˆæ¨¡å‹ï¼ˆå¸¦ç¼“å­˜ï¼‰+ è’¸é¦å®éªŒ
python run_experiments.py --dataset german

# ä»…è®­ç»ƒæ•™å¸ˆæ¨¡å‹ï¼ˆç»“æœä¼šè¢«ç¼“å­˜ï¼‰
python run_experiments.py --dataset german --stage teacher

# ä»…è¿è¡Œè’¸é¦å®éªŒï¼ˆéœ€è¦å·²æœ‰ç¼“å­˜çš„æ•™å¸ˆæ¨¡å‹ï¼‰
python run_experiments.py --dataset german --stage distill

# å¼ºåˆ¶é‡æ–°è®­ç»ƒæ•™å¸ˆæ¨¡å‹
python run_experiments.py --dataset german --force

# è¿è¡Œæ‰€æœ‰æ•°æ®é›†
python run_experiments.py --dataset all

# æŒ‡å®šGPUè®¾å¤‡
python run_experiments.py --dataset german --device 0

# å¿«é€Ÿå¯åŠ¨è„šæœ¬
python quick_start.py german
```

**è§£è€¦æ¶æ„çš„ä¼˜åŠ¿ï¼š**
- âœ… æ•™å¸ˆæ¨¡å‹è®­ç»ƒä¸è’¸é¦è¿‡ç¨‹åˆ†ç¦»
- âœ… è®­ç»ƒå¥½çš„æ•™å¸ˆæ¨¡å‹å’ŒSHAPå€¼è‡ªåŠ¨ç¼“å­˜åˆ° `results/teacher_cache/`
- âœ… é‡å¤å®éªŒæ—¶è‡ªåŠ¨è·³è¿‡æ•™å¸ˆè®­ç»ƒé˜¶æ®µ
- âœ… æ”¯æŒå•ç‹¬è¿è¡Œæ•™å¸ˆè®­ç»ƒæˆ–è’¸é¦é˜¶æ®µ
- âœ… æ•™å¸ˆé€‰æ‹©ç»“æœä¿å­˜åˆ° Excel ä¾¿äºæŸ¥çœ‹

**ä¼ ç»Ÿæ–¹å¼ï¼ˆä»ç„¶æ”¯æŒï¼‰ï¼š**

```bash
# å•ä¸€å…¥å£ï¼šmain.pyï¼ˆå»ºè®®å…ˆç”¨ n-runs=1 åšæœ€å°éªŒè¯ï¼‰
python main.py run --datasets german --n-runs 1

# å››ä¸ªæ•°æ®é›†ï¼šgerman, australian, uci, xinwang
python main.py run --datasets german australian uci xinwang --n-runs 1
```

è¯´æ˜ï¼šå®éªŒé»˜è®¤è¾“å‡ºåˆ° `results/`ï¼Œå¹¶åœ¨ `Manuscript_FI/Manuscript_FI/Figure/`ï¼ˆè‹¥å­˜åœ¨ï¼‰ä¿å­˜è®ºæ–‡ç”¨å›¾ï¼ˆSHAP/æ¶ˆèï¼‰ã€‚

### 3) å•ç‹¬ç”Ÿæˆè®ºæ–‡ Figure

```bash
# Fig.1ï¼šæŒ‰â€œå„æ•°æ®é›†å®é™…ä½¿ç”¨çš„ Teacherâ€é‡ç®— Top-10 SHAP å¹¶è¦†ç›–ä¿å­˜
python main.py shap --datasets german australian uci xinwang

# Fig.2ï¼šç”Ÿæˆæ¶ˆèå›¾ï¼ˆè‹¥ç¼ºå°‘ *_ablation.xlsxï¼Œå¯åŠ  --compute å…ˆè®¡ç®—ï¼‰
python main.py ablation --datasets german australian uci xinwang --compute --n-runs 1
```

### 4) è§„åˆ™å¯¼å‡º

```bash
python main.py rules --model results/model_cache/<your_dt_model>.pkl --output-dir results/rules
```

## ç›®å½•ç»“æ„ï¼ˆä»¥å½“å‰ä»“åº“ä¸ºå‡†ï¼‰

```
FinancialInnovation/
â”œâ”€â”€ main.py                    # ä¼ ç»Ÿå®éªŒå…¥å£
â”œâ”€â”€ run_experiments.py         # è§£è€¦å®éªŒå…¥å£ï¼ˆæ¨èï¼‰
â”œâ”€â”€ quick_start.py             # å¿«é€Ÿå¯åŠ¨è„šæœ¬
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ german_credit.csv
â”‚   â”œâ”€â”€ australian_credit.csv
â”‚   â”œâ”€â”€ xinwang.csv
â”‚   â””â”€â”€ uci_credit.csv
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ teacher_cache/         # æ•™å¸ˆæ¨¡å‹å’ŒSHAPç¼“å­˜
â”‚   â”œâ”€â”€ figures/               # ç”Ÿæˆçš„å›¾è¡¨
â”‚   â””â”€â”€ rules/                 # æå–çš„è§„åˆ™
â”œâ”€â”€ Manuscript_FI/
â””â”€â”€ src/
    â”œâ”€â”€ data/preprocessor.py
    â”œâ”€â”€ models/{baselines.py, neural.py}
    â”œâ”€â”€ distillation/{dt_distiller.py, losses.py, trainer.py}
    â”œâ”€â”€ experiments/
    â”‚   â”œâ”€â”€ runner.py          # å®éªŒè¿è¡Œå™¨
    â”‚   â””â”€â”€ teacher_trainer.py # æ•™å¸ˆæ¨¡å‹è®­ç»ƒå™¨
    â””â”€â”€ visualization/{plots.py, nature_plots.py}
```

### åŸºçº¿æ¨¡å‹è¯´æ˜

Teacheré€‰æ‹©é˜¶æ®µä¼šè®­ç»ƒä»¥ä¸‹æ‰€æœ‰åŸºçº¿æ¨¡å‹ï¼š

| ç±»åˆ« | æ¨¡å‹ | è¯´æ˜ |
|-----|------|------|
| Linear | LR-Ridge, LR-Lasso, LR-ElasticNet | é€»è¾‘å›å½’ (L2/L1/ElasticNet) |
| Kernel | SVM-RBF, SVM-Linear | æ”¯æŒå‘é‡æœº |
| Tree | DT | å†³ç­–æ ‘ |
| Instance-based | KNN | Kè¿‘é‚» |
| Probabilistic | NB | æœ´ç´ è´å¶æ–¯ |
| Ensemble (Optuna) | RF-Tuned, GBDT-Tuned, XGBoost-Tuned, LightGBM-Tuned, CatBoost-Tuned | Optunaè¶…å‚æ•°ä¼˜åŒ– |
| Neural | CreditNet | è‡ªå®šä¹‰ç¥ç»ç½‘ç»œ |

### ç¼“å­˜æ–‡ä»¶è¯´æ˜

æ•™å¸ˆæ¨¡å‹ç¼“å­˜ (`results/teacher_cache/`):
- `{dataset}_teacher_cache.json` - æ•™å¸ˆæ¨¡å‹å…ƒä¿¡æ¯ï¼ˆåç§°ã€AUCã€è¶…å‚æ•°ç­‰ï¼‰
- `{dataset}_teacher_{model}.pkl` - è®­ç»ƒå¥½çš„æ•™å¸ˆæ¨¡å‹
- `{dataset}_teacher_shap.npz` - é¢„è®¡ç®—çš„SHAPå€¼
- `{dataset}_all_models_index.json` - æ‰€æœ‰ä¿å­˜æ¨¡å‹çš„ç´¢å¼•

æ•™å¸ˆé€‰æ‹©ç»“æœä¿å­˜åˆ° `results/{dataset}_teacher_selection.xlsx`

## ğŸ“ Theoretical Foundations

### Theorem 1: Temperature-Interpretability Tradeoff

$$\mathbb{E}[\|p_S - p_T\|_2] \leq \frac{C_1}{\sqrt{\tau}} + C_2 \cdot \exp\left(-\frac{\tau}{\tau_0}\right)$$

### Theorem 2: Generalization Bound for SHAP-guided Distillation

$$\epsilon_S \leq \epsilon_T + O\left(\sqrt{\frac{k \cdot \log k}{n}}\right) + O\left(d_{\max}^{-1}\right) + O\left(\frac{1}{\tau}\right)$$

### Theorem 3: Feature Selection Consistency

$$P\left(|S_k \cap S_k^*| \geq (1-\delta)k\right) \geq 1 - 2\exp\left(-\frac{n\delta^2}{2}\right)$$

## ğŸ”¬ Baseline Models

| Model | Category | Reference |
|-------|----------|-----------|
| LR-Ridge | Linear | Hosmer & Lemeshow (2000) |
| LR-Lasso | Linear | Tibshirani (1996) |
| LR-ElasticNet | Linear | Zou & Hastie (2005) |
| SVM-RBF | Kernel | Cortes & Vapnik (1995) |
| RF | Ensemble | Breiman (2001) |
| GBDT | Ensemble | Friedman (2001) |
| XGBoost | Ensemble | Chen & Guestrin (2016) |
| LightGBM | Ensemble | Ke et al. (2017) |
| CatBoost | Ensemble | Prokhorenkova et al. (2018) |

## è¾“å‡ºä¸å‘½åè§„èŒƒï¼ˆä¸è®ºæ–‡ä¸€è‡´ï¼‰

- åŸºå‡†è¡¨ï¼š`results/<dataset>_baseline.xlsx`
- è’¸é¦è¡¨ï¼š`results/<dataset>_distillation.xlsx`ï¼Œæ–¹æ³•åä½¿ç”¨è®ºæ–‡å£å¾„ï¼š
  - `Teacher`
  - `Student Baseline (DT)`
  - `VanillaKD`
  - `SoftLabelKD`
  - `SHAP-KD`
  - `SHAP-KD (Adaptive)`ï¼ˆå¦‚å¯ç”¨ï¼‰
- æ¶ˆèè¡¨ï¼š`results/<dataset>_ablation.xlsx`
- è§„åˆ™å¯¼å‡ºï¼š`results/rules/<dataset>_SHAP-KD_rules.(txt|xlsx)`
- SHAP é‡è¦æ€§å›¾ï¼š`Manuscript_FI/Manuscript_FI/Figure/shap_<dataset>_top10.png`ï¼ˆè‹¥ Figure ç›®å½•å­˜åœ¨ï¼‰

## å¸¸è§é—®é¢˜

- Windows ä¸­æ–‡è·¯å¾„ï¼šå·²åœ¨ SHAP ç»˜å›¾ä¸­é»˜è®¤ `n_jobs=1` é¿å…å¹¶è¡Œç¼–ç é—®é¢˜ã€‚
- CatBoost ç”Ÿæˆ `catboost_info/`ï¼šå·²åœ¨ä»£ç ä¸­è®¾ç½® `allow_writing_files=False`ï¼Œä¸å†ç”Ÿæˆè¯¥ç›®å½•ã€‚

## ğŸ“Š Example Results

### German Credit Dataset - Distillation Results

| Model | AUC | Accuracy | F1 | Interpretable |
|-------|-----|----------|-----|---------------|
| Teacher (Best Baseline) | 0.867 | 0.834 | 0.821 | âŒ |
| DT-Baseline | 0.712 | 0.695 | 0.683 | âœ… |
| **SHAP-KD-DT (Ours)** | **0.845** | **0.812** | **0.798** | âœ… |

### Rule Extraction Example

```
[R1] (Samples: 245, Confidence: 87.35%)
  IF Status_A14 <= 0.23 AND Age <= 2.45 AND Duration <= 0.15
  THEN credit_risk = Non-default

[R2] (Samples: 123, Confidence: 82.11%)
  IF Status_A14 <= 0.23 AND Age <= 2.45 AND Duration > 0.15
  THEN credit_risk = Default
```

## ğŸ“ Citation

If you use this code in your research, please cite:

```bibtex
@article{author2024sakd,
  title={SHAP-guided Adaptive Knowledge Distillation for Interpretable Credit Scoring},
  author={Author, A. and Author, B.},
  journal={Financial Innovation},
  year={2024}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

